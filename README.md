# ğŸ§  FactRAG: Gemini-Powered Fact-Checking Assistant

A **Retrieval-Augmented Generation (RAG)** chatbot designed to fact-check claims using **Wikipedia evidence** and **Google Gemini (Generative AI)**.  
This project uses **LangChain**, **FAISS**, and **Hugging Face embeddings** to retrieve and verify factual information, inspired by the **FEVER dataset** structure.

---

## ğŸš€ Features

- ğŸ§© **RAG-based pipeline**: Combines retrieval (FAISS + HuggingFaceEmbeddings) with generation (Gemini).
- ğŸ” **Wikipedia-based evidence search** via FEVER-style `wiki-pages` data.
- ğŸ’¬ **Fact verification chatbot** using Gemini 2.5 Flash Lite model.
- ğŸ§  **Custom vector store builder** with chunking for efficient retrieval.
- âš¡ Modular code: each function separated into a clear, reusable module.
- ğŸ”’ Secrets handled safely using `.env` file (no hardcoded tokens).

---

## ğŸ“ Project Structure

```
Fact_check_RAG_chatbot/
â”‚
â”œâ”€â”€ app.py                        # Optional Streamlit app (for UI)
â”œâ”€â”€ build_vectorstore.py           # Builds FAISS store from Wikipedia text chunks
â”œâ”€â”€ config.py                      # Global configs, paths, model names, API keys
â”œâ”€â”€ data_conversion.py             # Converts & normalizes FEVER-like datasets
â”œâ”€â”€ evidence.py                    # Evaluates & extracts evidence sentences/pages
â”œâ”€â”€ fever_wiki.py                  # Loads & cleans FEVER Wikipedia data
â”œâ”€â”€ hf_utils.py                    # Hugging Face utilities (whoami, etc.)
â”œâ”€â”€ rag_chat.py                    # Core Gemini-powered RAG chatbot logic
â”œâ”€â”€ utils.py                       # Helper text cleaning functions
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .env.example                   # Example environment file (fill your tokens here)
â””â”€â”€ README.md                      # Project documentation
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Aditya-Thakur-87/FactRAG-Gemini-Powered-Fact-Checking-Assistant.git
cd FactRAG-Gemini-Powered-Fact-Checking-Assistant
```

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python -m venv venv
source venv/bin/activate      # (Linux/Mac)
venv\Scripts\activate       # (Windows)
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create `.env` file from example
```bash
cp .env.example .env
```

Then open `.env` and set your keys:
```
GOOGLE_API_KEY=your_google_gemini_api_key_here
```

---

## ğŸ§  Workflow Overview

### ğŸ”¹ 1. Data Loading
Load the FEVER dataset and Wikipedia dumps using `data_conversion.py` and `fever_wiki.py`.

### ğŸ”¹ 2. Data Cleaning & Evidence Extraction
Clean wiki pages and extract claim-evidence pairs via `evidence.py`.

### ğŸ”¹ 3. Build FAISS Vectorstore
Split Wikipedia text into overlapping chunks and embed them using Hugging Face sentence models.
```bash
python build_vectorstore.py
```

### ğŸ”¹ 4. Run Fact-Check Chatbot
Use Gemini + FAISS retriever pipeline to verify claims.
```bash
python rag_chat.py
```

Example Query:
```
Claim: "Source Code had Jake Gyllenhaal in it?"
â†’ Output: SUPPORTS (with brief reasoning)
```

---

## ğŸ§© Key Components

### `build_vectorstore.py`
- Uses `RecursiveCharacterTextSplitter` for chunking Wikipedia text.  
- Embeds chunks using `HuggingFaceEmbeddings`.  
- Saves FAISS index locally for efficient retrieval.

### `rag_chat.py`
- Loads FAISS retriever and Google Gemini LLM.  
- Uses a **LangChain pipeline** (`PromptTemplate` â†’ `Retriever` â†’ `Gemini LLM`).  
- Classifies each claim as `SUPPORTS`, `REFUTES`, or `NOT ENOUGH INFO`.

### `fever_wiki.py`
- Loads all FEVER Wikipedia JSONL files.  
- Cleans noise tokens like `-LRB-`, `-RRB-`, etc.  
- Returns structured sentence dictionaries for fast lookup.

---

## ğŸ’¡ Example Flow

```
1ï¸âƒ£ Input Claim: "The Great Wall of China is visible from space."
2ï¸âƒ£ Retriever: Finds Wikipedia sentences about the Great Wall.
3ï¸âƒ£ LLM: Gemini verifies evidence â†’ returns "REFUTES"
```

---

## ğŸ“¦ Example `.env`
```
GOOGLE_API_KEY=AIzaSyXXXXXXXXXXXXXXXX
```

Keep this file private â€” **never commit it** to GitHub!

---

## ğŸ§° Requirements

- Python 3.9+  
- Dependencies listed in `requirements.txt`:
  ```
  datasets
  pandas
  tqdm
  langchain_huggingface
  langchain_text_splitters
  langchain_community
  langchain_core
  huggingface_hub
  python-dotenv
  faiss-cpu
  langchain_google_genai
  ```

(Use `faiss-gpu` if you have CUDA support.)

---

## âš™ï¸ Advanced Usage

You can integrate this project with **Streamlit** for a web UI:

```bash
streamlit run app.py
```

Or adapt it for an **API backend** with FastAPI / Flask.

---

## ğŸ§© Future Improvements

- ğŸ” Add NLI (Natural Language Inference) layer for contradiction detection  
- âš¡ Improve retrieval ranking with hybrid search (BM25 + embeddings)  
- ğŸ§  Fine-tune on FEVER dataset for better factual reasoning  
- ğŸª¶ Add response confidence scores and source citations  

---

